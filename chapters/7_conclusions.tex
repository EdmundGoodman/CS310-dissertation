\chapter{Conclusions}
\label{ch:conclusions} % 500 words intro

\textbf{This chapter is now complete - but wasn't in the first three chapter draft submission!}

This project shows that Rust is suitable for performant and production implementations of High-Performance Computing codebases, answering the titular question. We conclude this as a result of three factors.

Firstly, \Cref{ch:translation} shows that it is possible to translate non-trivial existing codebases representative of High-Performance Computing workloads from C++ into Rust, including leveraging both shared and distributed memory parallelism through the \texttt{rayon} and \texttt{mpi} crates. These translations provide significant benefits to developer productivity.
% Consider re-phrasing this paragraph?
These include reduced effort spent debugging as a result of memory and concurrency safety guarantees and the rich type system, along with quantitative models of cost using the \texttt{scc} tool suggesting around a $1.63 \times$ increase.

Secondly, \Cref{ch:performance} shows that the performance of Rust translations of non-trivial C++ codebases closely approaches their reference implementations, with at worst around a $1.5 \times$ slowdown incurred across parallelism strategies. In addition to this, the Rust translations exhibit similar strong and weak scaling properties to the original C++ implementations, demonstrating its capability to scale to the extent required for High-Performance Computing workloads.

Finally, Rust's performance and productivity are likely to improve faster than C++, as it is a relatively young language, with lots of space to grow in the maturity of its package ecosystem and optimising compilers, further tipping the calculus in Rust's favour.
% Lots of space to grow sounds informal?

These factors taken in combination demonstrate Rust's suitability for High-Performance Computing applications, as despite its performance not matching C++, it provides commensurate benefits in developer productivity such as its compiler guarantees of memory and thread safety.

This project was a success, as it achieved all of its ``Must have'' and ``Should have'' objectives, shown in Appendix \ref{sec:project-requirements}. These include translating, equivalence checking, and undertaking a performance analysis of a High-Performance Computing mini-app across serial, shared memory, and distributed memory parallelism approaches. In addition to this, two ``Could have'' objectives relating to the equivalence checking were dropped, which allowed time for the development of tooling for reproducibly running and aggregating performance experiments. This tool facilitated deep performance analysis of the HPCCG translation, but also stands on its own as a helpful utility for engineers working in High-Performance Computing, as validated by the industry review.


\section{Reflection}
\label{sec:reflection} % 800 words

On reflection, I am immensely proud of the work I have completed in the course of this project. Coming in to the project, I did not have a good way to estimate how long translation tasks, so generously scheduled time in my project specification to undertake these tasks. It transpired that I was able to complete the translation of the serial and parallel implementations faster than expected, which allowed me to focus on the stretch goals of the project. The initially planned stretch goal was extending the translation effort to include an assessment of the Rust bindings to MPI. This presented an interesting technical challenge of using complex Rust structures within an API which does not exactly map the C++ implementation of the MPI specification.

In addition to this, empowered by incredibly helpful conversations with my supervisor, I also chose to extend the project by building tooling to facilitate performance measurements on High-Performance Computing resources using Slurm. I found this very fulfilling, as I personally enjoy building tooling, and was able to apply knowledge about what makes real-world tools effective that I learnt on my year in industry. In my opinion, this is one of the stand-out aspects of this project, as it not only was it incredibly helpful during my performance analysis, but can also be used as an open source software product going forward.


\section{Future work}
\label{sec:future-work} % 250 words

Whilst HPCCG is around an order of magnitude longer than any of the Rust codebases examined in existing literature, it is one of the shortest mini-apps in the Mantevo suite. In addition to this, other mini-apps are more influential in within this space, with HPCCG just being the first to introduce the idea. As a result of this, one avenue for future work is translating and analysing a longer, more influential mini-app, for example MiniMD \cite{osti_1231191} or HPCG \cite{dongarra2015hpcg}.

Secondly, equivalence checking is a very broad and complex field. As such, future work could easily be derived from this section. For example, a framework beyond the proof-of-concept for the \texttt{autocxx} approach to test-driven development could be developed, for example by using Rust macros for ergonomic multiplexing between C++ and Rust function calls. In addition to this, comparison of generated LLVM IR for equivalence checking was dropped as out of scope for this project, but could still yield fruitful research.

Finally, publicising and maintaining open source tools requires a lot of effort. To maximise the impact of the HPC MultiBench, a possible avenue of future work is making it easily accessible, including publishing it on PyPI, and responding to bug and feature requests raised on GitHub.


\section{Open source work}
\label{sec:open-source-work} % 500 words

% UK-MAC PR for website
% autocxx integration tests PR
% HPCCG documentation, unit tests, and CMake build system

% Planned future work to add autocxx and rs-mpi documentation
