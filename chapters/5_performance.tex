%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% THIS CHAPTER IS NOT COMPLETE! %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Performance}
\label{ch:performance} % 2000-2500 words

\textbf{This chapter is not complete!}

As enumerated in the objectives summary section of the introduction \ref{ch:ssec:objectives-summary}, on of the three requirements for Rust's suitability as a language for High-Performance Computing is having a comparable performance to C++, one of the most commonly used languages in current usage.

This chapter provides an empirical assessment of the performance of the Rust translation of the HPCCG mini-app. As discussed in the background section introducing HPCCG \ref{ssec:hpccg}, this is representative of High-Performance Computing workloads, due to the design goals of Mantevo Suite mini-apps being representative of full applications to facilitate hardware-software co-design. We leverage this property to instead assess the Rust language's suitability for such workloads by comparing the performance of the Rust translation to the original C++ implementation.

This performance profiling will begin with the use of instrumentation tooling to identify hot-spots in source code, characterising the bottlenecks in the Rust and C++ compiled executables. This allows a direct comparison of compiled assembly, yielding a clear picture of ways in which the Rust language differs from C++. Then, the HPC MultiBench tool will be used to run and analyse direct measurements of the Rust and C++ codebases. This allows the characterisation and comparison of performance for strong and weak scaling, and parallelism approaches, along with the generation of roofline models.

\section{Profiling tools}
\label{sec:profiling-tools} % 500 words

Software profilers are a category of tools which are used to measure properties of running programs. They differ from static analysis tools, as they analyse programs dynamically as they run, usually through instrumentation inserted at compile time, rather than using the source code itself. Profilers are most often used to characterise the performance and memory usage of programs, and through instrumentation can identify ``hotspots'' -- code sections in the program which account for a disproportionate amount of the metric, such as overall runtime. This makes profilers useful for guiding optimisations, as engineering effort can be targeted at the portion of program which impacts performance most greatly.

Performance profilers can also be used to compare implementations of the same software in different languages. Comparing the  profiles of the programs on the same problem size can elucidate where one language loses performance over another, and give insights into key factors such as vectorisation and memory bandwidth utilisation.

We choose to use a variety of performance profilers, because some profilers provide many more metrics and analysis options, but typically at the expense of the simple and ergonomic user interface. As a result of this, we used \texttt{perf} for the majority of profiling tasks, as they provide a convenient command line interface for instrumentation statistical sampling. We also used the Intel\textregistered\ oneAPI\texttrademark\ suite of tools, including Intel\textregistered\ vTune\texttrademark and Intel\textregistered\ Advisor\texttrademark, as these provide a vast array of capabilities such as roofline analysis, but with a complex graphical-only interface.


\subsection{The \texttt{perf} profiler}
\label{ssec:perf-profiler}

\texttt{perf} is a performance analysis tool which has been part of the Linux kernel since the 2.6.31 release in 2009 \cite{PerfcountersAddedMainline}. It uses a ``git-like'' subcommand based command line interface  \cite{de2010new}, which allows it to perform many functionalities. The \texttt{record} subcommand uses a single kernel syscall to instrument statistical sampling or program performance, and the \texttt{report} subcommand presents an analysis of this recorded data.

The \texttt{perf} profiler was used throughout the translation process to identify hotspots in the code. The benefit of this process was two-fold. Firstly, it allowed manual performance-guided optimisation, allowing prioritisation of engineering effort to ensure the Rust implementation was a fair representation of the full extent of the languages capabilities when comparing it to C++. Secondly, the hotspots identified provided a strong insight into the parts of Rust programs that fall short of C++, which informs the assessment of the suitability of Rust for High-Performance computing applications.

% As discussed in the introduction
The Rust programming language places a strong focus on the prevention of undefined behaviour, including enforcing memory and thread safety. The key insight of the language was that many of these guarantees against undefined behaviour can be made at compile time, through the ownership model enforced by the borrow checker. However, there is not enough information at compile time to fully guarantee these characteristics. For example, creating a vector of a length provided by user input at run time is a common operation within many programs. However, if the programmer accesses this vector by a fixed index in the source code, the compiler cannot guarantee the indexing operation is within the bounds of this vector, since its size is not known until runtime. To avoid undefined behaviour, Rust checks the bounds of every indexing operations to guarantee that the index is not out of range, but this incurs a performance cost -- roughly doubling the time taken for vector indexing. To avoid this check in performance critical applications when the bounds are already guaranteed, Rust provides the \mintinline{rust}{get_unchecked} function, which does not perform the bound check. This performance cost can be seen through comparing \texttt{perf} reports when using the default bounds checked indexing in Figure \ref{fig:perf-checked}, against unchecked indexing in Figure \ref{fig:perf-unchecked}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{images/5_performance/perf_checked_op.png}
    \caption{A screenshot of the \text{perf} report of a Rust translation of HPCCG using the default checked indexing.}
    \label{fig:perf-checked}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{images/5_performance/perf_unchecked_op.png}
    \caption{A screenshot of the \text{perf} report of a Rust translation of HPCCG using the unchecked indexing.}
    \label{fig:perf-unchecked}
\end{figure}

From these figures, we can see that the the bounds checking operation dominate the total runtime of the program, with $23.83 + 5.79 = 29.62$ percent of the runtime being taken up by the \mintinline{rust}{vector[matrix.list_of_inds[start_ind + j]]} operation in the bounds checked version, but only $4.17 + 2.67 + 3.66 = 10.5$ percent in the version without bounds checking. The empirical result of a $2.82\times$ speed-up for array indexing, a very common operation in High-Performance computing workloads, demonstrates the utmost importance of understanding and leveraging the full extent of the Rust language to be able to write performant software.

% Zero-cost abstractions
% iterators as a zero-cost abstraction? are they?

\subsection{The Intel\textregistered\ oneAPI\texttrademark\ suite}
\label{ssec:intel-advisor-profiler}
% Intel vTune Advisor
% Roofline model

\subsubsection{Roofline models}
\label{sssec:roofline-models}

% Introducing roofline models

% Using Intel Advisor
% Set of commands to run the models - part of a HPC MultiBench workflow

The Intel\textregistered\ Advisor tool is part of the Intel\textregistered\ oneAPI\texttrademark\ suite. It is ``'' \cite{}, and can be used to generate roofline plots. This is commonly done using its graphical user interface, but it is possible to also generate plots as minified HTML files from the command line. Listing \ref{listing:roofline-generation} shows the sequence of commands required to generate the roofline plots for an executable. 

\begin{listing}[H]
    \begin{minted}[linenos,breaklines]{bash}
advisor -collect roofline -project-dir ./ -- ./test_HPCCG
advisor --report=roofline --project-dir=./ --report-output=./roofline.html
    \end{minted}
    \caption{The commands required generate roofline models from the command line.}
    \label{listing:roofline-generation}
\end{listing}

Using these plots, we can characterise whether the computational kernels are memory or compute bound in each language, which gives an insight into how their performance can be improved. Roofline plots can be applied to multi-threaded and distributed workloads, however assuming a uniform processor architecture, the degree of parallelism does not significantly impact whether the kernels are computer or memory bound. As such, roofline plots for multi-threaded and distributed workloads are not included here, as they are not relevant and often less clear. Figure \ref{} shows the roofline plot for the C++ implementation of HPCCG, and Figure \ref{} for plot for the Rust implementation.

% Figure

% Figure

From these plots, we can see that both the C++ and Rust implementations appear to be mostly memory bound, with the DRAM bandwidth limiting the performance of the functions.

We can see that the \texttt{waxpby} in the C++ is amenable to vectorisation, and as such is able exceed the scalar compute roofline.

C++ has both a higher arithmetic intensity and rate of floating point operations.


Performance profilers provide a very powerful tool for identifying and optimising away hotspots in running programs. However, profilers are typically best suited for measuring many performance metrics in a fixed configuration, such as with a set number of processor threads and MPI ranks. To assess Rust's suitability for High-Performance Computing, we only needed a few metrics such as runtime and FLOPs, but wanted to measure how these varied across a wide range of metrics, with statistical confidence. As a result of this, we switched to a direct measurement approach driven by the HPC MultiBench tool, which was designed for this purpose.

\section{Direct measurement}
\label{sec:direct-measurement} % 2000 words

For Rust to be a suitable language for High-Performance Computing workloads, it must have a comparable performance across both a range of parallelism approaches, from serial execution to multi-threading and message passing across a compute cluster, and for large data volumes. To assess this, we used a wall clock approach to time the original C++ and the translated Rust implementations of HPCCG across a variety of problem sizes, and with a variety of thread counts and MPI sizes.

\subsection{Experimental methodology}
\label{ssec:experimental-methodology}

% In the intro to the book Performance Tuning of Scientific Applications, David Bailey suggests nine guidelines for presenting performance results without misleading the reader. Paraphrasing only slightly, these are: 

The experiments are fully defined by the YAML configuration files for the HPC MultiBench tool, providing extremely strong reproducibility characteristics. The salient features this provides include driving the programs across a range of inputs and configurations, along with supporting re-runs to give statistical confidence in the results.

For all experiments in this results section, the programs are run five times. The slowest run is then always discarded as an outlier, due to the possibility of machine noise or network instability for MPI workloads.

The original HPCCG implementation provides a number of different timers which measure the computational kernels. These include clock ticks, resource usage, wall time, and MPI timing intrinsics. By default, resource usage is used for serial and threaded compilations, and MPI timing intrinsics when MPI is used. However, the resource usage timer records the sum of the times for each thread. As a result of this, the \texttt{-DWALL} compiler flag was set to use the wall time. This allows representative comparisons to be made, as otherwise Rust may record faster times for short runs as a result of Rayon's work-stealing threading model. Finally, the UNIX \texttt{time} utility was also used to assess the total runtime including matrix setup, rather than just computational kernel runtimes.

On Kudu, 60GB of RAM was used, and on Avon 40GB was used, due to hardware limitations. During development, smaller RAM sizes were used, resulting in significantly degraded performance as a result of the mesh sizes exceeding allocated RAM, resulting in memory thrashing \cite{pattersonHennessyComputerOrganisationArchitecture}. To mitigate this, these very large RAM sizes were used, which guarantees thrashing does not occur since the mesh size does not exceed the amount of memory used, even for mesh sizes of $400 \times 400 \times 400$.


\subsubsection{Reproducibility}
\label{sssec:parallelism-approaches-reproducibility}

The raw data files and test plan YAML files for the results are available in the base and \texttt{\_test\_plan} directories of the \texttt{hpccg-rs-kudu-results} and \texttt{hpccg-rs-avon-results} repositories for the two compute systems respectively. Listing \ref{listing:serial-data-interactive} shows the command to launch the interactive user interface for the Kudu and Avon test plans respectively. When run locally, this allows the aggregation and analysis of the generated results to be viewed. If run on the appropriate batch computer system, the test benches can be re-run with the ``Run Test Plan'' button.

\begin{listing}[H]
    \begin{minted}[linenos]{bash}
# For the DCS Kudu batch compute system
poetry run python3 -m hpc_multibench \
    -y generated_results/hpccg-rs-kudu-results/_test_plans/parallelism.yaml \
    interactive
# For the SCRTP Avon batch compute system
poetry run python3 -m hpc_multibench \
    -y generated_results/hpccg-rs-avon-results/_test_plans/parallelism.yaml \
    interactive
    \end{minted}
    \caption{The commands required to interactively view and re-run the performance experiments for the parallelism approaches test benches.}
    \label{listing:serial-data-interactive}
\end{listing}

This yet again shows the power of the HPC MultiBench tool beyond the example use case shown in section \ref{ssec:hpc-multibench-replication-study}, as the experimental results presented in the previous section can easily be reviewed and even re-run, using a single command.


\subsubsection{System specifications}
\label{sssec:system-specifications}

During the course of experimentation, three different compute resources were used: Athena, the author's personal laptop; Kudu, the DCS batch compute system; and Avon, the Warwick SCRTP High-Performance Computing resource. Athena was used for the translation effort and initial testing, but not for any experimental results. However, since tests during the development process informed decisions made during the design process, its system specifications are relevant. Kudu was used for the majority of testing and the project presentation demo, as it is easy to access and has short queue times. Avon was used for later tests to confirm results, and for very large tests which exceeded Kudu's capacity.

Allow for reproducibility of the reported test data, the hardware specifications for the machines used as follows, with the results of \texttt{lscpu} for the machines are listed in Appendix \ref{sec:hardware-specifications} for completeness.

\begin{itemize}
    \item Athena has a \texttt{Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz} with eight logical cores.
    \item Kudu has a \texttt{Intel(R) Xeon(R) CPU E5-2660 v3 @ 2.60GHz} with 40 logical cores.
    \item Avon has a \texttt{Intel(R) Xeon(R) Platinum 8268 CPU @ 2.90GHz} with 48 logical cores.
\end{itemize}

The \texttt{lstopo} tool can be used to draw a graphical representation of both the hardware composing the system, and its topology. This gives a further insight into the hardware being used to run the tests, beyond the CPU model. Figures \ref{fig:athena-topology}, \ref{fig:kudu-topology} and \ref{fig:avon-topology} show the hardware topologies of the Athena, Kudu, and Avon systems respectively. For Kudu and Avon, \texttt{slurm} is used to dispatch jobs, so the commands are run from within a \texttt{slurm} job to be representative of the compute nodes rather than the login nodes of the cluster.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{images/5_performance/athena-topology.png}
    \caption{A diagram of a hardware topology of Athena.}
    \label{fig:athena-topology}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{images/5_performance/kudu-topology.png}
    \caption{A diagram of a hardware topology of Kudu.}
    \label{fig:kudu-topology}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{images/5_performance/avon-topology.png}
    \caption{A diagram of a hardware topology of Avon.}
    \label{fig:avon-topology}
\end{figure}

The software versions used for benchmarking across the three systems are enumerated in the following table:

\begin{table}[H]
    \caption{A table showing the software versions across the three compute resources.}
    \label{table:perfTools}
    \begin{tabular}{|p{0.24\linewidth}||p{0.2\linewidth}|p{0.2\linewidth}|p{0.2\linewidth}|}
    \hline
    \textbf{Software name} & \textbf{Athena} & \textbf{Kudu} & \textbf{Avon} \\
    \hline\hline
    Operating system & EndeavourOS 2023.03.26 & Rocky Linux 8.9                & CentOS Linux 8.4.2105          \\\hline
    Linux kernel     & 6.6.24-1-lts                     & 4.18.0-513.18.1. el8\_9.x86\_64 & 4.18.0-305.88.1. el8\_4.x86\_64 \\\hline
    rustc            & 1.73.0                           & 1.75.0                         & 1.75.0                         \\\hline
    clang            & 17.0.6                           & 16.0.6                         & 13.0.1                         \\\hline
    g++              & 13.2.1                           & 9.2.0                          & 11.3.0                         \\\hline
    OpenMP           & 4.5                              & 4.5                            & 4.5                            \\\hline
    rayon            & 1.8.0                            & 1.8.0                          & 1.8.0                          \\\hline
    Open MPI         & 5.0.2                            & 4.0.5                          & 4.1.4                          \\\hline
    rs-mpi           & 0.7.0                            & 0.7.0                          & 0.7.0                         \\\hline
    \end{tabular}
\end{table}


\subsection{Strong scaling}
\label{ssec:strong-scaling}

% What is strong scaling
Patterson and Hennessy define strong scaling as ``measuring the speed-up [due to parallelisation] while keeping the problem size fixed'' \cite{pattersonHennessyComputerOrganisationArchitecture}. This can be measured by recording the wall clock time taken for a fixed problem, whilst varying the degree of parallelisation, given by number of threads or MPI ranks. It can be used to show how adding more computational resources to a problem effects its performance. A perfect speedup due to parallelisation would decrease execution time linearly with the number of resources added. However, programs with a serial component cannot achieve this perfect speed-up as a corollary of Amdahl's law \cite{amdahlsLaw}:

\begin{equation}
    S = \frac{1}{f + \frac{1-f}{P}}
\end{equation}

Where $f$ denotes the proportion of execution time spent on the serial component, $P$ the degree of parallelisation, and $S$ the total speedup of the system as a result of parallelisation. For problems well-suited to parallelisation, we expect to see strong speedup approach the upper bound for performance following Amdahl's law.

% Strong scaling applied to HPCCG
In the context of HPCCG, strong scaling can be measured for single-node (multi-threading only) and multi-node (multi-threading and message passing). Figures \ref{} and \ref{} compare the results of the C++ and Rust implementations for strong scaling across single-node and multi-node approaches.

% Figures

% Summary
In summary,

\subsection{Weak scaling}
\label{ssec:weak-scaling}

% What is weak scaling
Patterson and Hennessy define weak scaling as ``measuring the speed-up while keeping the problem size fixed'' \cite{pattersonHennessyComputerOrganisationArchitecture}. This can be measured by recording the wall clock time taken, whilst varying the problem size at the same rate as the varying the degree of parallelisation, given by number of threads or MPI ranks. Since the workload grows with the number of resources added, perfect weak scaling is when the execution time remains constant as both factors are increased.

% Gustafson’s Law 
Unlike strong scaling, we cannot apply Amdahl's law to characterise weak scaling, since it assumes a fixed problem size. However, this extended case of variable problem size was characterised in 1988 in Gustafson's paper ``Re-evaluating Amdahl's law'' \cite{gustafsonReevaluatingAmdahlLaw1988}. Gustafson's law estimates the speedup, $S$ as a result of parallelisation in terms of the number of processors $N$, and the fractions of time executing the parallel and serial parts of the program, $p$ and $s$ respectively:

\begin{align}
    S &= s + p \times N \\
      &= N + (1 - N) \times s
\end{align}

% Weak scaling applied to HPCCG
In the context of HPCCG, as with strong scaling, weak scaling can again be measured for single-node (multi-threading only) and multi-node (multi-threading and message passing). Figures \ref{} and \ref{} compare the results of the C++ and Rust implementations for weak scaling across single-node and multi-node approaches.

% Figures

% Summary
In summary,


\subsection{Parallelism approaches}
\label{ssec:parallelism-approaches}

% TODO: cite
In modern High-Performance Computing systems, the majority of performance is achieved through parallelism. As a result of this, for Rust to be suitable for use in High-Performance Computing workloads, it must be able to achieve parallel compute performance similar to that of currently used languages, like C++. This section provides an empirical analysis of the performance of Rust as compared with C++ for increasingly parallel workloads, from serial as a reference to shared memory parallelism through multi-threading and distributed memory parallelism through message passing.

\subsection{Serial execution}
\label{ssec:multi-threaded}

Before exploring various parallelism approaches, it is important to measure a point of reference, in the form of serial execution of the program. In addition to just being a point of reference, the performance serial execution itself is an important metric. Almost program leveraging parallelism will have serial sections, and even if these are very short they can take up a significant proportion of a programs runtime for highly parallel programs, by Amdahl's law \cite{amdahlsLaw}. As a result of this, an empirical assessment comparing the performance of Rust with C++ workloads is highly relevant to the suitability of Rust for High-Performance Computing.

To assess serial performance, we ran the C++ and Rust executables over a range of mesh sizes, from $100 \times 100 \times 100$ to $300 \times 300 \times 300$, incrementing each axis size by $50$ each time. We expect the performance to scale with the total size of the mesh, which is the cube of the edge size. For the serial tests, all runs were conducted on a single node in the compute cluster, with a single task per node, and exclusive use of that node to reduce machine noise from other processes. As with all tests, 60GB of RAM was used on Kudu, and 40GB was used on Avon, to avoid memory thrashing for large mesh sizes, and performance is measured as wall time through the UNIX \texttt{time} utility.

Figures \ref{} and \ref{} show line and bar charts for the results of the serial test bench on Kudu, and Figures \ref{} and \ref{} show the same charts for runs on Avon.



In summary, Rust 

We can also see that tests run on Avon and Kudu have very similar performance characteristics. This is encouraging, since it suggests that Rust is portable across compute clusters topologies, albeit having only tested on Intel CPUs. As a result of this, for future diagrams, only the runs from Kudu will be shown, unless otherwise stated. The diagrams for Avon runs can be generated using the HPC MultiBench tool from the data provided in the \texttt{hpccg-rs-avon-results} repository, as discussed in section \ref{sssec:parallelism-approaches-reproducibility}.
% NOTE: Or could be shown in Appendix, or just shown inline - this isn't trying to hide anything, its literally just 50 diagrams take a tonne of space...


\subsection{Multi-threading}
\label{ssec:multi-threaded}

Having evaluated serial execution, the next parallelisation strategy to consider is shared memory parallelism through multi-threading. This is typically used for parallelism within a single machine, but it can also be used in combination with MPI for nodes in a cluster, as discussed in section \ref{multi-node-mpi}. As it is such a ubiquitous mechanism of parallelisation, along with frameworks such as OpenMP and Rayon which provide convenient abstractions over it, multi-threading is a critical aspect of writing performant code in High-Performance Computing.

To assess multi-threaded performance, we ran the C++ and Rust executables over both a range of mesh sizes, from $100 \times 100 \times 100$ to $400 \times 400 \times 400$, incrementing each axis size by $50$ each time, and a range of thread counts, from $1$ to $32$, doubling each time. For the parallel tests, all runs were conducted on a single node in the compute cluster, with a single task per node, and 32 threads allocated per task, along with exclusive use of that node to reduce machine noise from other processes. As with all tests, 60GB of RAM was used on Kudu, and 40GB was used on Avon.
% NOTE: This is cut down to avoid duplication from serial paragraph

Figures \ref{} and \ref{} show 

From Figure \ref{} which shows execution time relative to C++, we can see that for small meshes Rust with Rayon outperforms C++ with OpenMP increasingly with higher thread counts. For $100 \times 100 \times 100$ meshes with 32 threads, Rust takes $0.66 \pm 0.08 \times$ less runtime. This is likely because Rayon uses a work-stealing thread scheduling methodology, which means it avoids the overhead of allocating many threads for tasks too small to fully leverage them. However, for the largest workload of $400 \times 400 \times 400$ rusts begins to significantly trail C++, with 32 threads being $1.578 \pm 0.023 \times$ slower. This slower runtime appears to converge for very large mesh sizes, for example with 8 threads, meshes with edge lengths of $300$ and $400$ overlap uncertainty intervals at $1.49 \pm 0.12$ and $1.51 \pm 0.11$ respectively. This convergence appears to occur later for higher thread counts, but further experimentation on a more capable machine would be required to confirm this. The results from runs on Avon match those from Kudu, with the slowdown across threads converging at around $1.5 \pm 0.25$.

In summary, Rust remains performant in multi-threading workloads, but trails C++ in performance with around a $1.5 \times$ slow down for large, highly parallel workloads. However, the benefits of the ease of programming and thread safety guarantees resulting from Rust and Rayon may justify this slow down in some High-Performance Computing applications.

\subsection{MPI}
\label{ssec:mpi}

Shared memory parallelism is a very powerful technique for enhancing program performance. However, its efficacy is upper bounded by being constrained to a single machine with a shared memory architecture. In order to scale beyond this, distributed memory parallelism must be leveraged. This is required for many High-Performance Computing applications, as the largest supercomputers are all composed of clusters of many machines \cite{HomeTOP500}. As discussed in the translation section \ref{}, Rust provides MPI bindings which facilitate this.

To assess performance using MPI for message passing, we ran the C++ and Rust executables over both a range of mesh sizes, from $25 \times 25 \times 25$ to $250 \times 250 \times 250$, incrementing each axis size first by $25$, then by $50$ each time, and a range of nodes $1$, $2$, and $4$, with one task per node. For the MPI implementation, mesh size is constrained by the reference implementation constant value \mintinline{c++}{const int max_external = 100000;}. As a result of this, experiments ran only up to $250 \times 250 \times 250$ rather than $400 \times 400 \times 400$ for parallel implementations. Future work could include increasing this value and fixing any associated bugs, then running HPCCG across many nodes on a much larger mesh. 
% TODO large run with this turned up, then reference it here.

Figures \ref{} and \ref{} show 

% Analysis

In summary,

\subsection{MPI with Multi-threading}
\label{ssec:mpi-multithreading}

Shared and distributed memory parallelism can be used in tandem, with multi-threading within machines, which then communicate with each other through message passing. This allows programmers to leverage desirable properties from both approaches, such as the low-overhead performance of multi-threading in combination with the scalability of message passing.

This assessment shows a compares a best-case scenario for MPI with Multi-threading, which best characterises a likely use case in High-Performance Computing. Four nodes are used, with one task per node, and 32 threads per task. As such, four MPI ranks are used in combination with 32 threads for a total parallelism degree of 128 concurrent execution paths. This configuration was then driven over the same test range as MPI, from $25 \times 25 \times 25$ to $250 \times 250 \times 250$, incrementing each axis size first by $25$, then by $50$ each time. This is again constrained by the \texttt{max\_external} constant in the reference implementation.

Figures \ref{} and \ref{} show 

% Analysis

In summary,


\subsection{Performance portability frameworks}
\label{ssec:performance-portability-frameworks}

Finally, performance portability frameworks, such as Kokkos \cite{KokkosEcosystem}, are commonly used within High-Performance Computing to allow writing software which can run across a variety of hardware. However, such frameworks often incur a performance cost over hand-optimised implementations targeted at specific hardware. The fact that these frameworks are common, despite this performance cost, motivates the idea that Rust could be suitable for High-Performance Computing as a result of its productivity benefits, despite its performance impact.

This assessment compares the Rust, Kokkos, and C++ executables performance over a range of mesh sizes, from $25 \times 25 \times 25$ to $400 \times 400 \times 400$, incrementing each axis size first by $25$, then $50$, then $100$ for the remaining increments. As with the parallel assessment, a single node and a single task per node is used, and the implementations are compared with 32 threads each.

Figures \ref{} and \ref{} show 

% Analysis

In summary,



\section{Summary of results}
\label{sec:performance-results}

% Performance

% Productivity